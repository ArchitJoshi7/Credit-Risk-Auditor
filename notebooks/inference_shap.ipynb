# 2_predict_explain.ipynb

import pandas as pd
import numpy as np
import joblib
import shap
import json
import os
from datetime import datetime
from uuid import uuid4

# Paths
MODEL_PATH = "../models/xgb_model.pkl"
DATA_PATH = "../data/bank-additional-full.csv"

# Load model
model = joblib.load(MODEL_PATH)

# Load dataset for feature reference
df_raw = pd.read_csv(DATA_PATH, sep=';')
df_raw.drop(columns=["duration"], inplace=True)
df_raw["y"] = df_raw["y"].map({"yes": 1, "no": 0})
df_encoded = pd.get_dummies(df_raw, drop_first=True)

# Align new data to match model input
feature_columns = df_encoded.drop("y", axis=1).columns

# Simulate user input (manually or from UI)
# You can replace this with new data dynamically
sample_input = df_encoded.drop("y", axis=1).iloc[0]  # first row
X_input = sample_input.values.reshape(1, -1)

# Prediction
prediction = model.predict(X_input)[0]
prediction_proba = model.predict_proba(X_input)[0][1]

# SHAP explainability
explainer = shap.Explainer(model)
shap_values = explainer(X_input)

# SHAP value dict
shap_dict = dict(zip(feature_columns, shap_values.values[0]))

# Prepare input dict
input_dict = dict(zip(feature_columns, X_input[0]))

# Combine into a log dictionary
decision_log = {
    "log_id": str(uuid4()),
    "timestamp": datetime.utcnow().isoformat(),
    "prediction": int(prediction),
    "prediction_proba": float(np.round(prediction_proba, 4)),
    "input_features": input_dict,
    "shap_values": shap_dict,
    "model_name": "XGBoost",
    "model_version": "1.0"
}

# Preview
print("Prediction:", "✅ YES" if prediction else "❌ NO")
print("Confidence:", f"{prediction_proba:.2f}")
print("\nTop 5 Feature Contributions (SHAP):")
sorted_shap = sorted(shap_dict.items(), key=lambda x: abs(x[1]), reverse=True)[:5]
for feat, val in sorted_shap:
    print(f"{feat}: {val:.4f}")
