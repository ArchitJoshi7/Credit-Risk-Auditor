# 1_preprocess_data.ipynb

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
import joblib
import os

# Paths
DATA_PATH = "../data/bank-additional-full.csv"
PROCESSED_DATA_PATH = "../data/processed_data.csv"
SCALER_PATH = "../models/scaler.pkl"

# Load raw data
df = pd.read_csv(DATA_PATH, sep=';')

# Drop leakage-prone columns
df.drop(columns=["duration"], inplace=True)

# Encode target
df["y"] = df["y"].map({"yes": 1, "no": 0})

# One-hot encode categorical features
df_encoded = pd.get_dummies(df, drop_first=True)

# Scale numerical features
X = df_encoded.drop("y", axis=1)
y = df_encoded["y"]

num_cols = X.select_dtypes(include=["int64", "float64"]).columns
scaler = StandardScaler()
X[num_cols] = scaler.fit_transform(X[num_cols])

# Combine scaled features with target
df_processed = pd.DataFrame(X, columns=X.columns)
df_processed["y"] = y.values

# Save processed data and scaler
os.makedirs("../models", exist_ok=True)
df_processed.to_csv(PROCESSED_DATA_PATH, index=False)
joblib.dump(scaler, SCALER_PATH)

print("‚úÖ Preprocessing complete.")
print(f"üìÅ Processed data saved to: {PROCESSED_DATA_PATH}")
print(f"üì¶ Scaler saved to: {SCALER_PATH}")
